{"class_name": "Tokenizer", "config": {"num_words": null, "filters": "!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n", "lower": true, "split": " ", "char_level": false, "oov_token": null, "document_count": 5156, "word_counts": "{\"physics\": 1345, \"mathematics\": 1221, \"chemistry\": 2590}", "word_docs": "{\"physics\": 1345, \"mathematics\": 1221, \"chemistry\": 2590}", "index_docs": "{\"2\": 1345, \"3\": 1221, \"1\": 2590}", "index_word": "{\"1\": \"chemistry\", \"2\": \"physics\", \"3\": \"mathematics\"}", "word_index": "{\"chemistry\": 1, \"physics\": 2, \"mathematics\": 3}"}}